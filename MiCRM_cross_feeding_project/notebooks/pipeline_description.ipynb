{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb641469",
   "metadata": {},
   "source": [
    "# Pipeline for Microbiome Cross-Feeding Interactions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6520382d",
   "metadata": {},
   "source": [
    "The following workflow gives in detail the steps that I used to generate the pipeline when running the script [`get_interactions.py`](https://github.com/ferreirav/CMEEResearchProject/blob/main/MiCRM_cross_feeding_project/code/get_interactions.py).\n",
    "In sum, this script will subset the data from the Earth Microbiome Project by unique sample IDs, retrieve their organism composition, generate metabolic models and calculate the interaction potential."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be6f5254",
   "metadata": {},
   "source": [
    "### **Step 1:** Loading data...\n",
    "\n",
    "\n",
    "I have loaded specifically 3 datasets:\n",
    "\n",
    "- Samples data (filtered) from the EMP and used in [Machado et al. (2021)](https://www.pnas.org/doi/abs/10.1073/pnas.1421834112) - data can be directly downloaded [(here)](https://oc.embl.de/index.php/s/SbhoQa9YJoa748V/download) !\n",
    "\n",
    "- Respective Metadata [(accesssed in EMP repo)](https://github.com/biocore/emp/tree/master/data/mapping-files)\n",
    "\n",
    "- and the Genome-Scale Model list for bacterial species [(accessed here)](https://github.com/cdanielmachado/embl_gems)\n",
    "\n",
    "The data was then merged by sample reference and extracted the specific features of interest.\n",
    "\n",
    "A more detailed steps description of this data exploration is available in another notebook [(explore_data_v4.ipynb)](https://github.com/ferreirav/CMEEResearchProject/blob/main/MiCRM_cross_feeding_project/notebooks/exploring_data.ipynb) !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd14bab6",
   "metadata": {},
   "source": [
    "### Step 2: Creating Python script with functions\n",
    "\n",
    "The script [`emp_data_wrang.py`](https://github.com/ferreirav/CMEEResearchProject/blob/main/MiCRM_cross_feeding_project/code/emp_data_wrang.py) contains three functions:\n",
    "\n",
    "- **get_data()** which generates the data described in step 1;\n",
    "\n",
    "\n",
    "- **download_ncbi_genome_temp()** which is a duplicate function of *download_ncbi_genome()* used in the `CarveMe` package but I have adapted it to download and decompress the `faa.gz` files according to sample being processed;\n",
    "\n",
    "- **get_genome()** takes the organism list from the sample and download each single acession reference using the above function.\n",
    "\n",
    "Also a CSV file with assembly accession and organism ID is created to be acessed later by a BASH script that will feed into the `carve` function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7522ef08",
   "metadata": {},
   "source": [
    "### Step 3: Calling `get_genome()`\n",
    "\n",
    "Then `get_genome()` function is called once provided with the sample relevant information to download the whole community genomes and stores these in a folder with sample name which will be remove once completed the carving of metabolic models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51438548",
   "metadata": {},
   "source": [
    "### Step 4: Calling BASH...\n",
    "\n",
    "At this stage, I will be calling a Bash script to run `CarveMe` and `SMETANA`.\n",
    "\n",
    "The BASH template for this step can be accessed [here](https://github.com/ferreirav/CMEEResearchProject/blob/main/MiCRM_cross_feeding_project/code/get_acessions.sh).\n",
    "\n",
    "Initially, to capture the sample IDs and other data, I create a copy of this same template and named it as the sample ID.\n",
    "\n",
    "To guide you through the bash script:\n",
    "\n",
    "1. I collect the filename (same as sample ID), define the PATHS and create directories for each unique sample;\n",
    "\n",
    "2. In a *for loop* I concatenate every line from the CSV file that contains accession number and organism ID, extract these and parse into the `CarveMe` command using:\n",
    "        \n",
    "        carve \"acession\".faa.gz -o \"organism_name\".xml    \n",
    "    This will generate metabolic models for individual organisms and store these in an output folder with samples IDs.\n",
    "<br>\n",
    "\n",
    "3. Completed *carving*, the genomes folders and respective CSV file are deleted;\n",
    "\n",
    "4. Collected the metabolic models, I use `SMETANA` to calculate community interaction and resource overlap using `global` options of the package:\n",
    "            \n",
    "        smetana -v *.xml -o \"SAMPLE\"     \n",
    "    To calculate the individual and pair-wise interactions we need to use the `detailed` flag, as follows:\n",
    "    \n",
    "        smetana -v -d *.xml -o \"SAMPLE\"\n",
    "\n",
    "#### <span style=\"color:red\">**NOTE:**</span> These last steps, especially the calculation of individual interaction potential, is causing few errors, as:\n",
    "- NAs in the *MIP* for community analysis:\n",
    "\n",
    "     - **Solution** provided in [GitHub issue](https://github.com/cdanielmachado/smetana/issues/13) is to use the flag `--flavor bigg`. This calculates exchanges reactions using BiGG, otherwise searches for unbalanced reactions which include an internal \"sink\".\n",
    "     \n",
    "- 'MUS: Failed to find a minimal growth medium for ' + org_id:\n",
    "\n",
    "    - **suggested** to use flag `--molweight` as minimises the minimal media composition predicted by minimising the total mass of the consumed substrates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c072dd6",
   "metadata": {},
   "source": [
    "### Step 5: Multiprocessing\n",
    "\n",
    "As last step on the script, I have implemented a process-based parallelism with `multiprocessing` module.\n",
    "\n",
    "I call the function `get_data()` and retrieve only the sample list by using index `[0]`. I will then use `map()` to execute the main function `processing_interactions()` within the possible pool of CPUs available and giving as argument, for each run, an individual sample name from the `sample_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed24e88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
